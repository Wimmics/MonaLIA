{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MonaLIA Full Set Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdflib import Graph, URIRef, BNode, Literal\n",
    "from rdflib import RDF, RDFS, XSD\n",
    "from rdflib.namespace import SKOS\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MonaLIA library from the package in the subfolder of the notebook folder\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import importlib \n",
    "import MonaLIA.util.metadata_helpers \n",
    "import MonaLIA.data.image_dataset\n",
    "import MonaLIA.model.train as model\n",
    "\n",
    "importlib.reload(MonaLIA.util.metadata_helpers)\n",
    "#importlib.reload(MonaLIA.data.image_dataset)\n",
    "\n",
    "from MonaLIA.data.image_dataset import JocondeDataset\n",
    "from MonaLIA.util import metadata_helpers as helpers\n",
    "from MonaLIA.util.metadata_helpers import monalia, jcl, notice, thesaurus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdflib ver. 5.0.0\n",
      "SPARQLWrapper ver. 1.8.5\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "print('rdflib ver.', rdflib.__version__)\n",
    "\n",
    "import SPARQLWrapper\n",
    "print('SPARQLWrapper ver.', SPARQLWrapper.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Joconde'\n",
    "\n",
    "\n",
    "images_root = 'C:/Joconde/joconde'\n",
    "descr_path = 'C:/Datasets/Joconde/forty classes'\n",
    "image_description_file = os.path.join(descr_path, 'dataset1.csv')\n",
    "\n",
    "multi_label = True\n",
    "multi_crop = False\n",
    "batch_size = 4\n",
    "\n",
    "model_name = 'inception_v3'\n",
    "#model_param_file = '../output/Inception_v3_Joconde_20_classes.1000.1.pth'\n",
    "model_checkpoint_file = '../../MonaLIA/output/inception_v3_Joconde_40_classes.test.1000.3.4.checkpoint.pth.tar'\n",
    "model_image_size = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset JocondeDataset\n",
      "    Number of datapoints: 85797\n",
      "    Root location: C:/Joconde/joconde\n",
      "    Description file: C:/Datasets/Joconde/forty classes\\dataset1.csv\n",
      "    Number of classes: 40\n",
      "    Number of uniqie labels: 4893\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=299, interpolation=PIL.Image.BILINEAR)\n",
      "               CenterCrop(size=(299, 299))\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "           )\n",
      "    Labels: {'ange': 3382, 'arbre': 10537, 'armure': 1805, 'bateau': 4956, 'bateau à voiles': 1678, 'casque': 1524, 'cavalier': 2333, 'chapeau': 2701, 'cheval': 7928, 'chien': 3344, 'château': 2898, 'couronne': 3193, 'croix': 2296, 'de face': 3766, 'de profil': 5329, 'drapeau': 1248, 'draperie': 3083, 'en buste': 10458, 'feuille': 1390, 'fleur': 5972, 'lion': 1274, 'livre': 3074, 'main': 2272, 'maison': 5164, 'mer': 1944, 'montagne': 2209, 'mouton': 1290, 'nu': 8009, 'nuage': 1291, 'nudité': 2218, 'oiseau': 4890, 'pont': 2016, 'robe': 1273, 'table': 1532, 'tour': 1035, 'uniforme': 1757, 'voiture à attelage': 1969, 'à mi-corps': 4820, 'église': 4698, 'épée': 2187}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if model_name == 'inception_v3':\n",
    "    dataset_mean =  [0.5, 0.5, 0.5]\n",
    "    dataset_std  =  [0.5, 0.5, 0.5]\n",
    "\n",
    "elif model_name == 'vgg16_bn':\n",
    "    dataset_mean =  image_transforms.joconde_mean_animals \n",
    "    dataset_std  =  image_transforms.joconde_std_animals \n",
    "       \n",
    "else:\n",
    "    raise ValueError('unexplored model')\n",
    "    \n",
    "if (multi_crop):\n",
    "    test_trans = transforms.Compose([\n",
    "                    transforms.Resize(max(256, model_image_size)),\n",
    "                    transforms.FiveCrop(model_image_size),\n",
    "                    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])), # returns a 4D tensor\n",
    "                    NormalizeMultiCrop(mean = dataset_mean,\n",
    "                                         std = dataset_std)\n",
    "                    ])\n",
    "else:\n",
    "\n",
    "    test_trans = transforms.Compose([\n",
    "        #PadToSquare(padding_mode='wrap'),\n",
    "        #transforms.Resize((model_image_size, model_image_size)), \n",
    "        transforms.Resize(model_image_size),\n",
    "        transforms.CenterCrop(model_image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = dataset_mean,\n",
    "                             std = dataset_std),\n",
    "    ])\n",
    "    \n",
    "\n",
    "\n",
    "test_set = JocondeDataset(image_description_file, \n",
    "                        images_root,\n",
    "                        dataset_name = 'all_classes',\n",
    "                        exclude_labels= []  ,\n",
    "                        label_column='label',\n",
    "                        multiple_labels = multi_label, \n",
    "                        #filter_dict= {'usage': ['test']}, \n",
    "                        add_columns=['ref', 'repr'],\n",
    "                        transform=test_trans)\n",
    "\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=2)\n",
    "\n",
    "class_count = len(test_set.classes)\n",
    "class_names = test_set.classes\n",
    "\n",
    "print('Test', test_set)\n",
    "print('    Labels:', test_set.labels_count)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'arch', 'state_dict', 'best_acc', 'classes', 'threshold', 'elapsed_time'])\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(model_checkpoint_file)\n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not mer', 'mer']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "theClass = checkpoint['classes'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda?  True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "print('Using cuda? ', use_cuda)\n",
    "\n",
    "net = model.load_net(model_name = model_name, class_count=len(checkpoint['classes']))\n",
    "#net.load_state_dict(torch.load(model_param_file))\n",
    "net = net.to(device)\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "print(net.transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images total: 1000 of 85797\n",
      "images total: 2000 of 85797\n",
      "images total: 3000 of 85797\n",
      "images total: 4000 of 85797\n",
      "images total: 5000 of 85797\n",
      "images total: 6000 of 85797\n",
      "images total: 7000 of 85797\n",
      "images total: 8000 of 85797\n",
      "images total: 9000 of 85797\n",
      "images total: 10000 of 85797\n",
      "images total: 11000 of 85797\n",
      "images total: 12000 of 85797\n",
      "images total: 13000 of 85797\n",
      "images total: 14000 of 85797\n",
      "images total: 15000 of 85797\n",
      "images total: 16000 of 85797\n",
      "images total: 17000 of 85797\n",
      "images total: 18000 of 85797\n",
      "images total: 19000 of 85797\n",
      "images total: 20000 of 85797\n",
      "images total: 21000 of 85797\n",
      "images total: 22000 of 85797\n",
      "images total: 23000 of 85797\n",
      "images total: 24000 of 85797\n",
      "images total: 25000 of 85797\n",
      "images total: 26000 of 85797\n",
      "images total: 27000 of 85797\n",
      "images total: 28000 of 85797\n",
      "images total: 29000 of 85797\n",
      "images total: 30000 of 85797\n",
      "images total: 31000 of 85797\n",
      "images total: 32000 of 85797\n",
      "images total: 33000 of 85797\n",
      "images total: 34000 of 85797\n",
      "images total: 35000 of 85797\n",
      "images total: 36000 of 85797\n",
      "images total: 37000 of 85797\n",
      "images total: 38000 of 85797\n",
      "images total: 39000 of 85797\n",
      "images total: 40000 of 85797\n",
      "images total: 41000 of 85797\n",
      "images total: 42000 of 85797\n",
      "images total: 43000 of 85797\n",
      "images total: 44000 of 85797\n",
      "images total: 45000 of 85797\n",
      "images total: 46000 of 85797\n",
      "images total: 47000 of 85797\n",
      "images total: 48000 of 85797\n",
      "images total: 49000 of 85797\n",
      "images total: 50000 of 85797\n",
      "images total: 51000 of 85797\n",
      "images total: 52000 of 85797\n",
      "images total: 53000 of 85797\n",
      "images total: 54000 of 85797\n",
      "images total: 55000 of 85797\n",
      "images total: 56000 of 85797\n",
      "images total: 57000 of 85797\n",
      "images total: 58000 of 85797\n",
      "images total: 59000 of 85797\n",
      "images total: 60000 of 85797\n",
      "images total: 61000 of 85797\n",
      "images total: 62000 of 85797\n",
      "images total: 63000 of 85797\n",
      "images total: 64000 of 85797\n",
      "images total: 65000 of 85797\n",
      "images total: 66000 of 85797\n",
      "images total: 67000 of 85797\n",
      "images total: 68000 of 85797\n",
      "images total: 69000 of 85797\n",
      "images total: 70000 of 85797\n",
      "images total: 71000 of 85797\n",
      "images total: 72000 of 85797\n",
      "images total: 73000 of 85797\n",
      "images total: 74000 of 85797\n",
      "images total: 75000 of 85797\n",
      "images total: 76000 of 85797\n",
      "images total: 77000 of 85797\n",
      "images total: 78000 of 85797\n",
      "images total: 79000 of 85797\n",
      "images total: 80000 of 85797\n",
      "images total: 81000 of 85797\n",
      "images total: 82000 of 85797\n",
      "images total: 83000 of 85797\n",
      "images total: 84000 of 85797\n",
      "images total: 85000 of 85797\n",
      "images total: 85797 of 85797\n",
      "Finished scoring\n"
     ]
    }
   ],
   "source": [
    "activation = torch.softmax\n",
    "scores = model.score(net, test_loader, activation, save_to_file='scores.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the scores file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.load('..\\\\output\\\\scores.pt').cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85797, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10830765294429619"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "y_true = np.array(test_set.targets[:scores.shape[0]])\n",
    "y_score = scores.cpu().detach().numpy()\n",
    "\n",
    "labeled = np.sum(y_true ,  axis=1) > 0\n",
    "\n",
    "val_mAP = metrics.average_precision_score(y_true[labeled], y_score[labeled], average='macro')\n",
    "val_mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the classification results with the  KB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wds = \"http://localhost:3030/Joconde/query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not mer                                                             None\n",
       "mer        http://data.culture.fr/thesaurus/resource/ark:/67717/T523-618\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the URIs for the classes\n",
    "#class_terms =  pd.Series(index=test_set.classes)\n",
    "class_terms =  pd.Series(index=checkpoint['classes'], dtype=object)\n",
    "\n",
    "for i, t in enumerate(class_terms.index):\n",
    "    class_terms[t] = helpers.getJocondeTermByLabel_service(wds, t)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "class_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['not mer', 'mer'], dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_terms.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_vocab = \"REPR\" #\"DOMN\"\n",
    "classifier_name = '10 classes'\n",
    "classifier_descr = \"Classifier trained on images labeled by the top 10 most populated terms from the MiC's list of 100\"\n",
    "classifier_type = monalia.classifierRepresentedSubjectMultiLabel\n",
    "classifier_id = monalia.classifierTenClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "theClass = checkpoint['classes'][1]\n",
    "classifier_vocab = \"REPR\" #\"DOMN\"\n",
    "classifier_name = theClass\n",
    "classifier_descr = \"Binary classifier for category '%s'@fr. Param file: %s \" % (theClass , os.path.basename(model_checkpoint_file))\n",
    "classifier_type = monalia.classifierRepresentedSubjectBinary\n",
    "classifier_id = monalia['classifier_%s' % theClass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all_classes'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = helpers.create_graph()\n",
    "\n",
    "#New classifier class\n",
    "clsfier = URIRef(classifier_type)\n",
    "g.add((clsfier , RDF.type, RDFS.Class))\n",
    "g.add((clsfier , monalia.vocabID , Literal(classifier_vocab))) #Literal('DOMN')))\n",
    "\n",
    "\n",
    "clsfier_sp = URIRef(classifier_id) \n",
    "g.add((clsfier_sp , RDFS.subClassOf, clsfier))\n",
    "g.add((clsfier_sp , RDFS.label , Literal(classifier_name))) \n",
    "g.add((clsfier_sp , RDFS.comment , Literal(classifier_descr))) \n",
    "\n",
    "#g.bind(\"n\",notice)\n",
    "\n",
    "#g.namespace_manager.bind('skos', SKOS,  override=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_terms.index:\n",
    "    \n",
    "    if class_terms[i] is not None:\n",
    "        t = BNode()\n",
    "        g.add( (t, RDF.type, class_terms[i]) )\n",
    "        g.add( (t, SKOS.prefLabel, Literal(i, lang='fr')) )\n",
    "        g.add ((clsfier_sp , monalia.conatainsClass, t))\n",
    "    \n",
    "    \n",
    "    #g.add((clsfier_sp , monalia.conatainsClass, Literal(i , lang='fr') ))\n",
    "    #g.add( (t , RDF.type, class_terms[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix jcl: <http://jocondelab.iri-research.org/ns/jocondelab/> .\n",
      "@prefix ml: <http://ns.inria.fr/monalia/> .\n",
      "@prefix n: <https://jocondelab.iri-research.org/data/notice/> .\n",
      "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
      "@prefix t: <http://data.culture.fr/thesaurus/resource/ark:/67717/> .\n",
      "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "ml:classifierRepresentedSubjectBinary a rdfs:Class ;\n",
      "    ml:vocabID \"REPR\" .\n",
      "\n",
      "ml:classifier_mer rdfs:label \"mer\" ;\n",
      "    ml:conatainsClass [ a t:T523-618 ;\n",
      "            skos:prefLabel \"mer\"@fr ] ;\n",
      "    rdfs:comment \"Binary classifier for category 'mer'@fr. Param file: inception_v3_Joconde_40_classes.mer.1000.4.checkpoint.pth.tar \" ;\n",
      "    rdfs:subClassOf ml:classifierRepresentedSubjectBinary .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(g.serialize(format='n3', encoding='utf-8').decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, Done\n"
     ]
    }
   ],
   "source": [
    "top_k = scores.shape[1] \n",
    "\n",
    "#for i, row in classified_df.iterrows():\n",
    "for i, row in enumerate(test_set.samples):\n",
    "    \n",
    "    ref = row[2]\n",
    "    \n",
    "    classifier_bn = BNode()\n",
    "   \n",
    "    g.add( (notice[ref], monalia.imageClassifier, classifier_bn))\n",
    "    g.add( (classifier_bn, RDF.type,   clsfier_sp ))\n",
    "   \n",
    "\n",
    "    #reduce the number of stored prediction classes to top 5 scores\n",
    "    pred_scores, pred_labels =  torch.topk(scores[i] , top_k ,0)\n",
    "    \n",
    "           \n",
    "    #pred_score_dict = dict(zip( [test_set.classes[pl] for pl in pred_labels] , \n",
    "    pred_score_dict = dict(zip( [class_terms.index[pl] for pl in pred_labels] ,\n",
    "                                pred_scores.numpy()))\n",
    "    \n",
    "\n",
    "    for r, label in enumerate(pred_score_dict):\n",
    "        \n",
    "        if class_terms[label] is not None:\n",
    "            label_key_value = BNode()\n",
    "\n",
    "            g.add( (classifier_bn, monalia.detected, label_key_value) )\n",
    "            #g.add( (label_key_value, monalia.predictionRank, Literal(r, datatype=XSD.int) ) ) \n",
    "            #g.add( (label_key_value, monalia.label, Literal(label, lang='fr') ))#TODO: delete\n",
    "            g.add( (label_key_value, RDF.type, class_terms[label] )) \n",
    "            g.add( (label_key_value, monalia.score, Literal(round(pred_score_dict[label], 4) , datatype=XSD.float)))\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print (i, end=', ')\n",
    "    elif i == 2:     \n",
    "        sample_RDF = g.serialize(format='n3', encoding='utf-8').decode(\"utf-8\")\n",
    "        break\n",
    "            \n",
    "print(\"Done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix jcl: <http://jocondelab.iri-research.org/ns/jocondelab/> .\n",
      "@prefix ml: <http://ns.inria.fr/monalia/> .\n",
      "@prefix n: <https://jocondelab.iri-research.org/data/notice/> .\n",
      "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
      "@prefix t: <http://data.culture.fr/thesaurus/resource/ark:/67717/> .\n",
      "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "ml:classifierRepresentedSubjectBinary a rdfs:Class ;\n",
      "    ml:vocabID \"REPR\" .\n",
      "\n",
      "<https://jocondelab.iri-research.org/data/notice/50170000659> ml:imageClassifier [ a ml:classifier_mer ;\n",
      "            ml:detected [ a t:T523-618 ;\n",
      "                    ml:score \"0.0337\"^^xsd:float ] ] .\n",
      "\n",
      "<https://jocondelab.iri-research.org/data/notice/50350109897> ml:imageClassifier [ a ml:classifier_mer ;\n",
      "            ml:detected [ a t:T523-618 ;\n",
      "                    ml:score \"0.1147\"^^xsd:float ] ] .\n",
      "\n",
      "n:M0809027797 ml:imageClassifier [ a ml:classifier_mer ;\n",
      "            ml:detected [ a t:T523-618 ;\n",
      "                    ml:score \"0.0171\"^^xsd:float ] ] .\n",
      "\n",
      "ml:classifier_mer rdfs:label \"mer\" ;\n",
      "    ml:conatainsClass [ a t:T523-618 ;\n",
      "            skos:prefLabel \"mer\"@fr ] ;\n",
      "    rdfs:comment \"Binary classifier for category 'mer'@fr. Param file: inception_v3_Joconde_40_classes.mer.1000.4.checkpoint.pth.tar \" ;\n",
      "    rdfs:subClassOf ml:classifierRepresentedSubjectBinary .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample_RDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the classification results in RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../MonaLIA/output/inception_v3_Joconde_40_classes.test.1000.3.4.checkpoint.pth.tar'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_file_name = os.path.join('./Classification Results', 'full_dataset.Inception_v3_Joconde_40_classes.test.1000.3.4.ttl')\n",
    "g.serialize(destination=rdf_file_name, format='n3', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the graph if nesessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N21241ded5fd8438bb86790fdbfd1ed59 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rdflib\n",
    "from rdflib import Graph\n",
    "\n",
    "print('rdflib ver.', rdflib.__version__)\n",
    "\n",
    "rdf_file_name = 'humans and horses and birds and dogs.ttl'\n",
    "g_test = Graph()\n",
    "g_test.parse(rdf_file_name, format='n3', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'voiture \\\\xe0 attelage'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'voiture à attelage'.encode(\"ascii\",  errors=\"backslashreplace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
